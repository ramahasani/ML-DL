{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accompanied-representation",
   "metadata": {},
   "source": [
    "make various choices of dense layers, layer sizes and convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "viral-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1611557812\n",
      "2-conv-32-nodes-0-dense-1611557812\n",
      "3-conv-32-nodes-0-dense-1611557812\n",
      "1-conv-64-nodes-0-dense-1611557812\n",
      "2-conv-64-nodes-0-dense-1611557812\n",
      "3-conv-64-nodes-0-dense-1611557812\n",
      "1-conv-128-nodes-0-dense-1611557812\n",
      "2-conv-128-nodes-0-dense-1611557812\n",
      "3-conv-128-nodes-0-dense-1611557812\n",
      "1-conv-32-nodes-1-dense-1611557812\n",
      "2-conv-32-nodes-1-dense-1611557812\n",
      "3-conv-32-nodes-1-dense-1611557812\n",
      "1-conv-64-nodes-1-dense-1611557812\n",
      "2-conv-64-nodes-1-dense-1611557812\n",
      "3-conv-64-nodes-1-dense-1611557812\n",
      "1-conv-128-nodes-1-dense-1611557812\n",
      "2-conv-128-nodes-1-dense-1611557812\n",
      "3-conv-128-nodes-1-dense-1611557812\n",
      "1-conv-32-nodes-2-dense-1611557812\n",
      "2-conv-32-nodes-2-dense-1611557812\n",
      "3-conv-32-nodes-2-dense-1611557812\n",
      "1-conv-64-nodes-2-dense-1611557812\n",
      "2-conv-64-nodes-2-dense-1611557812\n",
      "3-conv-64-nodes-2-dense-1611557812\n",
      "1-conv-128-nodes-2-dense-1611557812\n",
      "2-conv-128-nodes-2-dense-1611557812\n",
      "3-conv-128-nodes-2-dense-1611557812\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers =[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-activation",
   "metadata": {},
   "source": [
    "put the choices to the previous code to see the best implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "#define a callback\n",
    "#NAME = \"Cats-vs-dog-cnn-64x2-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "#loading the features and labeled data\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "#normalize the pixel data\n",
    "X=np.array(X/255.0) #the max value of pixel is 255\n",
    "y=np.array(y)\n",
    "\n",
    "#modelling\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers =[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))#convolutional layer\n",
    "            model.add(Activation('relu'))#activation layer\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))#pooling layer\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())  # converts 3D feature maps to 1D feature vectors\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))#output layer\n",
    "            model.add(Activation('sigmoid'))#activation layer\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs =10, validation_split=0.3, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-universal",
   "metadata": {},
   "source": [
    "the best val accuracy is: 3 conv, 64 nodes per layer, 0 dense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blond-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1611557993\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 257s 470ms/step - loss: 0.6761 - accuracy: 0.5567 - val_loss: 0.5556 - val_accuracy: 0.7193\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 187s 342ms/step - loss: 0.5332 - accuracy: 0.7305 - val_loss: 0.4681 - val_accuracy: 0.7835\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 200s 366ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.4487 - val_accuracy: 0.7839\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 200s 366ms/step - loss: 0.4069 - accuracy: 0.8185 - val_loss: 0.4372 - val_accuracy: 0.8033\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 205s 376ms/step - loss: 0.3662 - accuracy: 0.8384 - val_loss: 0.4089 - val_accuracy: 0.8128\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 197s 361ms/step - loss: 0.3277 - accuracy: 0.8589 - val_loss: 0.3985 - val_accuracy: 0.8208\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 196s 358ms/step - loss: 0.3094 - accuracy: 0.8657 - val_loss: 0.3917 - val_accuracy: 0.8282\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 207s 380ms/step - loss: 0.2713 - accuracy: 0.8840 - val_loss: 0.3912 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 201s 369ms/step - loss: 0.2468 - accuracy: 0.8996 - val_loss: 0.3842 - val_accuracy: 0.8354\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 207s 380ms/step - loss: 0.2254 - accuracy: 0.9053 - val_loss: 0.3751 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "#define a callback\n",
    "#NAME = \"Cats-vs-dog-cnn-64x2-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "#loading the features and labeled data\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "#normalize the pixel data\n",
    "X=np.array(X/255.0) #the max value of pixel is 255\n",
    "y=np.array(y)\n",
    "\n",
    "#modelling\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers =[3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))#convolutional layer\n",
    "            model.add(Activation('relu'))#activation layer\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))#pooling layer\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())  # converts 3D feature maps to 1D feature vectors\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))#output layer\n",
    "            model.add(Activation('sigmoid'))#activation layer\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs =10, validation_split=0.3, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-breeding",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controversial-attitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Rama-Catdog-CNN.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Rama-Catdog-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-cooking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
